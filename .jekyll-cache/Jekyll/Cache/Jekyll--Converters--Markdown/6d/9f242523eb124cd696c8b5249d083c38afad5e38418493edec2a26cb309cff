I"ç<p>I am currently a forth-year Ph.D. student in Machine Learning and High-Performance Computing at Imperial College London, supervised by Prof. <a href="https://www.imperial.ac.uk/people/w.luk">Wayne Luk</a>. My current research focues on:</p>

<ul>
  <li>ML for Hardware System
    <ul>
      <li>Co-Design for Reconfigurable Accelerator: <a href="">DACâ€™22</a>, <a href="https://arxiv.org/pdf/2111.12787.pdf">ASP-DACâ€™22</a>, <a href="https://www.doc.ic.ac.uk/~wl/papers/20/iccd20hf.pdf">ICCDâ€™20</a></li>
      <li>ML-Assisted Qauntum EDA: <a href="">DACâ€™22</a></li>
    </ul>
  </li>
  <li>Hardware System for ML
    <ul>
      <li>Bayesian Neural Network: <a href="https://arxiv.org/abs/2002.00190">DACâ€™21</a>, <a href="">TCADâ€™22</a>, <a href="">TPDSâ€™22</a></li>
      <li>Convolutional Neural Network: <a href="https://www.doc.ic.ac.uk/~wl/papers/21/date21sl.pdf">DATEâ€™21</a>, <a href="https://www.doc.ic.ac.uk/~wl/papers/21/tnnls21sl.pdf">TNNLSâ€™21</a>, <a href="https://ieeexplore.ieee.org/abstract/document/9570135">TNNLSâ€™22</a>, <a href="https://ieeexplore.ieee.org/abstract/document/8825127">ASAPâ€™19</a>, <a href="https://www.doc.ic.ac.uk/~wl/papers/18/fpt18hf.pdf">FPTâ€™18</a></li>
      <li>Gragh or Recurrent Neural Network: <a href="">ISCASâ€™22</a>, <a href="https://www.doc.ic.ac.uk/~wl/papers/20/fccm20zq.pdf">FCCMâ€™20</a>, <a href="https://ieeexplore.ieee.org/abstract/document/9664799">TVLSIâ€™22</a></li>
    </ul>
  </li>
</ul>

<p>Our research also has received <strong>Best Paper Nomination</strong> at <a href="https://asap2019.csl.cornell.edu/program.html">ASAPâ€™19</a>, <a href="http://www.fpt18.sakura.ne.jp/program.html">FPTâ€™18</a>.</p>

<hr />

<h1 id="news">News!</h1>

<p><em>2022/02</em>: Two papers are accepted by DACâ€™22:</p>

<ul>
  <li>
    <font size="3"> â€œOptimizing Quantum Circuit Placement via Machine Learningâ€, Hongxiang Fan et al.</font>
  </li>
  <li>
    <font size="3"> "Fast Uncertainty Estimation by Accelerating Bayesian Transformers", Hongxiang Fan et al.</font>
  </li>
</ul>

<p><em>2022/02</em>: One paper titled â€œ<a href="">FPGA-based Acceleration for Bayesian Convolutional Neural Networks</a>â€ is accepted by TCAD.</p>

<p><em>2022/01</em>: One paper titled â€œ<a href="">Accelerating Bayesian Neural Networks via Algorithmic and Hardware Optimizations</a>â€ is accepted by TPDS.</p>

<p><em>2022/01</em>: One paper titled â€œ<a href="">Customizable FPGA-based Accelerator for Binarized Graph Neural Networks</a>â€ is accepted by ISCAS. This is my first time to supervise a first-year Ph.D. student to publish a conference paper as the corresponding author!</p>

<p><em>2021/12</em>: One co-author paper related recurrent neural network is accepted by TVLSI.</p>

<p><em>2021/11</em>: Joining Samsung AI Center, Cambridge as Research Intern. Working with Prof. <a href="http://niclane.org/">Nicholas Lane</a>, Dr. <a href="https://tech.cornell.edu/people/mohamed-abdelfattah/">Mohamed Abdelfattah</a> and Dr. <a href="https://www.thomaschau.uk/">Thomas C P Chau</a>.</p>

<p><em>2021/09</em>: One paper titled â€œ<a href="https://ieeexplore.ieee.org/abstract/document/9570135">High-Performance Acceleration of 2-D and 3-D CNNs on FPGAs Using Static Block Floating Point</a>â€ is accepted by TNNLS.</p>

<p><em>2021/09</em>: One paper titled â€œ<a href="https://arxiv.org/pdf/2111.12787.pdf">Algorithm and Hardware Co-design for Reconfigurable CNN Accelerator</a>â€ is accepted by ASP-DACâ€™22.</p>

<p>â€¦â€¦â€¦â€¦â€¦.</p>

<p><em>2019/07</em>: Our paper â€œF-E3D: FPGA-based Acceleration of An Efficient 3D Convolutional Neural Network for Human Action Recognitionâ€ receive <strong>Best Paper Nomination</strong> in <a href="https://asap2019.csl.cornell.edu/program.html">ASAPâ€™19</a>.</p>

<p>â€¦â€¦â€¦â€¦â€¦.</p>

<p><em>2018/12</em>: Our paper â€œA Real-Time Object Detection Accelerator with Compressed SSDLite on FPGAâ€ receive <strong>Best Paper Nomination</strong> in <a href="http://www.fpt18.sakura.ne.jp/program.html">FPTâ€™18</a>.</p>

<p>â€¦â€¦â€¦â€¦â€¦.</p>
:ET